{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Feature Selection</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv(\"review_meta_train.csv\")[\"rating\"]\n",
    "vote_funny=pd.read_csv(\"review_meta_train.csv\")[\"vote_funny\"]\n",
    "vote_cool=pd.read_csv(\"review_meta_train.csv\")[\"vote_cool\"]\n",
    "vote_useful=pd.read_csv(\"review_meta_train.csv\")[\"vote_useful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the average accuracies of 3 different feature representations: with 50, 100, and 200 features using 3 different\n",
    "classifiers. Choose the data file with highest average accuracy to be used in the next steps\n",
    "'''\n",
    "\n",
    "list_of_filenames = [\"review_text_train_doc2vec50.csv\", \n",
    "                   \"review_text_train_doc2vec100.csv\",\n",
    "                   \"review_text_train_doc2vec200.csv\"]\n",
    "list_of_Xs = [pd.read_csv(i, header=None) for i in list_of_filenames]\n",
    "list_of_clfs = [RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=2),\n",
    "              DummyClassifier(strategy=\"most_frequent\"),\n",
    "              svm.LinearSVC(max_iter=10000)]\n",
    "data_objects = [train_test_split(X, y_train, test_size=0.2, random_state=1) for X in list_of_Xs]\n",
    "list_of_X_train = [i[0] for i in data_objects]\n",
    "list_of_X_test = [i[1] for i in data_objects]\n",
    "list_of_y_train = [i[2] for i in data_objects]\n",
    "list_of_y_test = [i[3] for i in data_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file number: 0\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=False, random_state=2, verbose=0,\n",
      "                       warm_start=False) Accuracy: 0.7703954399714998\n",
      "DummyClassifier(constant=None, random_state=None, strategy='most_frequent') Accuracy: 0.6841824011400072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) Accuracy: 0.8138582116138225\n",
      "File: review_text_train_doc2vec50.csv\n",
      "Average accuracy: 0.7561453509084433\n",
      "Data file number: 1\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=False, random_state=2, verbose=0,\n",
      "                       warm_start=False) Accuracy: 0.7452796579978624\n",
      "DummyClassifier(constant=None, random_state=None, strategy='most_frequent') Accuracy: 0.6841824011400072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) Accuracy: 0.8192019950124688\n",
      "File: review_text_train_doc2vec100.csv\n",
      "Average accuracy: 0.7495546847167796\n",
      "Data file number: 2\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=False, random_state=2, verbose=0,\n",
      "                       warm_start=False) Accuracy: 0.7249732810830067\n",
      "DummyClassifier(constant=None, random_state=None, strategy='most_frequent') Accuracy: 0.6841824011400072\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) Accuracy: 0.8284645529034557\n",
      "File: review_text_train_doc2vec200.csv\n",
      "Average accuracy: 0.7458734117088232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for data_file_number in range(len(list_of_filenames)):\n",
    "    print(\"Data file number:\", data_file_number)\n",
    "    current_total_accuracy = 0\n",
    "    for clf in list_of_clfs:\n",
    "        clf.fit(list_of_X_train[data_file_number], list_of_y_train[data_file_number])\n",
    "        predictions = clf.predict(list_of_X_test[data_file_number])\n",
    "        accuracy = accuracy_score(predictions, list_of_y_test[0])\n",
    "        print(clf, \"Accuracy:\", accuracy)\n",
    "        current_total_accuracy += accuracy        \n",
    "    average_accuracy = current_total_accuracy/len(list_of_clfs)\n",
    "    print(\"File:\", list_of_filenames[data_file_number])\n",
    "    print(\"Average accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that the doc2vec representation with 50 features is better than the ones with 100 and 200 features, at least on preliminary classifiers which have not been carefully chosen or tuned. Now, let's see if adding the metadata (vote_funny, vote_cool, and vote_useful) helps the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=False, random_state=2, verbose=0,\n",
      "                       warm_start=False) Accuracy: 0.7682579266120413\n",
      "DummyClassifier(constant=None, random_state=None, strategy='most_frequent') Accuracy: 0.6841824011400072\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) Accuracy: 0.8163519771998575\n",
      "Average accuracy: 0.7562641016506353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "df_with_metadata=pd.read_csv(\"review_text_train_doc2vec50.csv\", header=None)\n",
    "df_with_metadata[\"vote_funny\"]=vote_funny\n",
    "df_with_metadata[\"vote_cool\"]=vote_cool\n",
    "df_with_metadata[\"vote_useful\"]=vote_useful\n",
    "\n",
    "X=df_with_metadata\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "list_of_clfs = [RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=2),\n",
    "                DummyClassifier(strategy=\"most_frequent\"),\n",
    "              svm.LinearSVC(max_iter=10000)]\n",
    "\n",
    "current_total_accuracy = 0\n",
    "for clf in list_of_clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(predictions, y_test)\n",
    "    print(clf, \"Accuracy:\", accuracy)\n",
    "    current_total_accuracy += accuracy        \n",
    "average_accuracy = current_total_accuracy/len(list_of_clfs)\n",
    "print(\"Average accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is very small, but adding these features indeed result in improved performance. So we will use those features as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Use the Doc2Vec representation with 50 features and vote information</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Work with training set and validation set</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile necessary elements and separate the class label\n",
    "df=pd.read_csv(\"review_text_train_doc2vec50.csv\", header=None)\n",
    "y_train=pd.read_csv(\"review_meta_train.csv\")[\"rating\"]\n",
    "vote_funny=pd.read_csv(\"review_meta_train.csv\")[\"vote_funny\"]\n",
    "vote_cool=pd.read_csv(\"review_meta_train.csv\")[\"vote_cool\"]\n",
    "vote_useful=pd.read_csv(\"review_meta_train.csv\")[\"vote_useful\"]\n",
    "\n",
    "df[\"class_label\"] = y_train\n",
    "df[\"vote_funny\"]=vote_funny\n",
    "df[\"vote_cool\"]=vote_cool\n",
    "df[\"vote_useful\"]=vote_useful\n",
    "\n",
    "X = df.drop(columns=[\"class_label\"])\n",
    "y = df[\"class_label\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Split the dataset into train and validation set\n",
    "\"\"\"\n",
    "df_train = df.sample(frac=0.8, replace=False, random_state=1)\n",
    "X_train = df_train.drop(columns=[\"class_label\"])\n",
    "y_train = df_train[\"class_label\"]\n",
    "\n",
    "df_val = df.drop(labels=df_train.index, axis='index')\n",
    "X_val = df_val.drop(columns=[\"class_label\"])\n",
    "y_val = df_val[\"class_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Accuracy scores of different classifiers</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(classifier, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Fit a model using X_train and y_train\n",
    "    Predictions based on X_val\n",
    "    Returns the predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Perform Grid Search to find the best parameters for Random Forest </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 50, 'n_estimators': 300, 'random_state': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={\"n_estimators\": [50, 100, 200, 300],\n",
    "            \"max_depth\": [2, 5, 10, 25, 50], \n",
    "            \"criterion\": [\"entropy\", \"gini\"],\n",
    "            \"random_state\": [2]}\n",
    "clf=GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Find validation set and training set accuracy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7760954755967224"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=300, max_depth=25, n_jobs=-1, random_state=2)  #GINI is already by default\n",
    "RF_predictions= train_predict(clf1, X_train, y_train, X_val, y_val)\n",
    "RF_Acc = accuracy_score(RF_predictions, y_val)\n",
    "RF_Acc    #Validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(clf1.predict(X_train), y_train)    #Training set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Find 0-R performance on the training and testing sets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6886968914224637"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3=DummyClassifier(strategy=\"most_frequent\")\n",
    "clf3.fit(X_train, y_train)\n",
    "accuracy_score(clf3.predict(X_train), y_train)   #Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6811542572141076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(clf3.predict(X_val), y_val)    #Validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Perform Grid Search to find the best parameters for SVM </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'max_iter': [100, 1000, 10000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={\"C\": [0.1, 1, 10, 100],\n",
    "           \"max_iter\": [100, 1000, 10000]}\n",
    "clf=GridSearchCV(estimator=svm.SVC(), param_grid=parameters, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 10000}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Find validation set and training set accuracy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8101175632347702"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = svm.LinearSVC(C=1, max_iter=10000)\n",
    "SVC_predictions = train_predict(clf4, X_train, y_train, X_val, y_val)\n",
    "SVC_Acc = accuracy_score(SVC_predictions, y_val)\n",
    "SVC_Acc    #Validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194976396187762"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(clf4.predict(X_train), y_train)    #Training accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Stacking (2 Fold)</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the train set into halves\n",
    "\"\"\"\n",
    "\n",
    "df_train_first_half=df_train.sample(frac=0.5)\n",
    "df_train_second_half=df_train.drop(labels=df_train_first_half.index, axis='index')\n",
    "\n",
    "X_train_first_half = df_train_first_half.drop(columns=[\"class_label\"])\n",
    "y_train_first_half = df_train_first_half[\"class_label\"]\n",
    "\n",
    "X_train_second_half = df_train_second_half.drop(columns=[\"class_label\"])\n",
    "y_train_second_half = df_train_second_half[\"class_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Using different base classifiers, fit the model using one half of the train set, and predict using the other half of the train set. The results of the prediction will become the training set for the stacker</H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest (using parameters found via grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_stacker = pd.DataFrame()\n",
    "\n",
    "base_clf1 = RandomForestClassifier(n_estimators=300, max_depth=25, n_jobs=-1, random_state=2)\n",
    "base_clf1.fit(X_train_first_half, y_train_first_half)\n",
    "rf_base_predictions = pd.DataFrame(base_clf1.predict_proba(X_train_second_half))\n",
    "df_for_stacker[\"RF_1Star\"] = rf_base_predictions[0]\n",
    "df_for_stacker[\"RF_3Star\"] = rf_base_predictions[1]\n",
    "df_for_stacker[\"RF_5Star\"] = rf_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_stacker2 = pd.DataFrame()\n",
    "\n",
    "base_clf1 = RandomForestClassifier(n_estimators=300, max_depth=25, n_jobs=-1, random_state=2)\n",
    "base_clf1.fit(X_train_second_half, y_train_second_half)\n",
    "rf_base_predictions = pd.DataFrame(base_clf1.predict_proba(X_train_first_half))\n",
    "df_for_stacker2[\"RF_1Star\"] = rf_base_predictions[0]\n",
    "df_for_stacker2[\"RF_3Star\"] = rf_base_predictions[1]\n",
    "df_for_stacker2[\"RF_5Star\"] = rf_base_predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes and Neural Network. No hyperparameter tuning is done here as we are not going to be analysing these systems; these are simply minor components of the stacking classifier. For the neural network, we simply guessed what might be effective hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf2 = GaussianNB()\n",
    "base_clf2.fit(X_train_first_half, y_train_first_half)\n",
    "gnb_base_predictions = pd.DataFrame(base_clf2.predict_proba(X_train_second_half))\n",
    "df_for_stacker[\"GNB_1Star\"] = gnb_base_predictions[0]\n",
    "df_for_stacker[\"GNB_3Star\"] = gnb_base_predictions[1]\n",
    "df_for_stacker[\"GNB_5Star\"] = gnb_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf2 = GaussianNB()\n",
    "base_clf2.fit(X_train_second_half, y_train_second_half)\n",
    "gnb_base_predictions = pd.DataFrame(base_clf2.predict_proba(X_train_first_half))\n",
    "df_for_stacker2[\"GNB_1Star\"] = gnb_base_predictions[0]\n",
    "df_for_stacker2[\"GNB_3Star\"] = gnb_base_predictions[1]\n",
    "df_for_stacker2[\"GNB_5Star\"] = gnb_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf3 = MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=1000)\n",
    "base_clf3.fit(X_train_first_half, y_train_first_half)\n",
    "nn_base_predictions = pd.DataFrame(base_clf3.predict_proba(X_train_second_half))\n",
    "df_for_stacker[\"NN_1Star\"] = nn_base_predictions[0]\n",
    "df_for_stacker[\"NN_3Star\"] = nn_base_predictions[1]\n",
    "df_for_stacker[\"NN_5Star\"] = nn_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf3 = MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=1000)\n",
    "base_clf3.fit(X_train_second_half, y_train_second_half)\n",
    "nn_base_predictions = pd.DataFrame(base_clf3.predict_proba(X_train_first_half))\n",
    "df_for_stacker2[\"NN_1Star\"] = nn_base_predictions[0]\n",
    "df_for_stacker2[\"NN_3Star\"] = nn_base_predictions[1]\n",
    "df_for_stacker2[\"NN_5Star\"] = nn_base_predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM (using parameters found via grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "base_clf4 = svm.LinearSVC(C=1, max_iter=10000)\n",
    "base_clf4.fit(X_train_first_half, y_train_first_half)\n",
    "svm_base_predictions = pd.DataFrame(base_clf4.decision_function(X_train_second_half))\n",
    "df_for_stacker[\"SVM_1Star\"] = svm_base_predictions[0]\n",
    "df_for_stacker[\"SVM_3Star\"] = svm_base_predictions[1]\n",
    "df_for_stacker[\"SVM_5Star\"] = svm_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "base_clf4 = svm.LinearSVC(C=1, max_iter=10000)\n",
    "base_clf4.fit(X_train_second_half, y_train_second_half)\n",
    "svm_base_predictions = pd.DataFrame(base_clf4.decision_function(X_train_first_half))\n",
    "df_for_stacker2[\"SVM_1Star\"] = svm_base_predictions[0]\n",
    "df_for_stacker2[\"SVM_3Star\"] = svm_base_predictions[1]\n",
    "df_for_stacker2[\"SVM_5Star\"] = svm_base_predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Meta classifier</H4>\n",
    "<H5>Grid Search</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'random_state': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={\"C\": [0.1, 1, 10, 20],\n",
    "           \"max_iter\": [100, 500, 1000, 10000],\n",
    "            \"penalty\": ['l1', 'l2'],\n",
    "           \"random_state\": [1]}\n",
    "clf=GridSearchCV(estimator=LogisticRegression(), param_grid=parameters, n_jobs=-1, cv=5)\n",
    "clf.fit(pd.concat([df_for_stacker, df_for_stacker2]), pd.concat([y_train_second_half, y_train_first_half]))\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8251981829518126"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_clf = LogisticRegression(C=1, penalty='l2', max_iter=100, random_state=1)\n",
    "meta_clf.fit(pd.concat([df_for_stacker, df_for_stacker2]), pd.concat([y_train_second_half, y_train_first_half]))\n",
    "meta_prediction = meta_clf.predict(pd.concat([df_for_stacker, df_for_stacker2]))\n",
    "accuracy_score(meta_prediction, pd.concat([y_train_second_half, y_train_first_half]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Generate validation set for the meta classifier from base classifiers predictions</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_for_stacker = pd.DataFrame()\n",
    "\n",
    "rf_base_predictions_val = pd.DataFrame(base_clf1.predict_proba(X_val))\n",
    "df_val_for_stacker[\"RF_1Star\"] = rf_base_predictions_val[0]\n",
    "df_val_for_stacker[\"RF_3Star\"] = rf_base_predictions_val[1]\n",
    "df_val_for_stacker[\"RF_5Star\"] = rf_base_predictions_val[2]\n",
    "\n",
    "gnb_base_predictions_val = pd.DataFrame(base_clf2.predict_proba(X_val))\n",
    "df_val_for_stacker[\"GNB_1Star\"] = gnb_base_predictions_val[0]\n",
    "df_val_for_stacker[\"GNB_3Star\"] = gnb_base_predictions_val[1]\n",
    "df_val_for_stacker[\"GNB_5Star\"] = gnb_base_predictions_val[2]\n",
    "\n",
    "nn_base_predictions_val = pd.DataFrame(base_clf3.predict_proba(X_val))\n",
    "df_val_for_stacker[\"NN_1Star\"] = nn_base_predictions_val[0]\n",
    "df_val_for_stacker[\"NN_3Star\"] = nn_base_predictions_val[1]\n",
    "df_val_for_stacker[\"NN_5Star\"] = nn_base_predictions_val[2]\n",
    "\n",
    "svm_base_predictions_val = pd.DataFrame(base_clf4.decision_function(X_val))\n",
    "df_val_for_stacker[\"SVM_1Star\"] = svm_base_predictions_val[0]\n",
    "df_val_for_stacker[\"SVM_3Star\"] = svm_base_predictions_val[1]\n",
    "df_val_for_stacker[\"SVM_5Star\"] = svm_base_predictions_val[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Meta classifier performance on validation set</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8170644816530104"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_predictions = meta_clf.predict(df_val_for_stacker)\n",
    "accuracy_score(meta_predictions, y_val)   #Validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Repeat the process to get the predictions for the test set</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Work with (complete) train set and test set, without validation set</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"review_text_test_doc2vec50.csv\", header=None)\n",
    "\n",
    "vote_funny=pd.read_csv(\"review_meta_train.csv\")[\"vote_funny\"]\n",
    "vote_cool=pd.read_csv(\"review_meta_train.csv\")[\"vote_cool\"]\n",
    "vote_useful=pd.read_csv(\"review_meta_train.csv\")[\"vote_useful\"]\n",
    "y_train=pd.read_csv(\"review_meta_train.csv\")[\"rating\"]\n",
    "\n",
    "df[\"class_label\"] = y_train\n",
    "df[\"vote_funny\"]=vote_funny\n",
    "df[\"vote_cool\"]=vote_cool\n",
    "df[\"vote_useful\"]=vote_useful\n",
    "\n",
    "vote_funny_test=pd.read_csv(\"review_meta_test.csv\")[\"vote_funny\"]\n",
    "vote_cool_test=pd.read_csv(\"review_meta_test.csv\")[\"vote_cool\"]\n",
    "vote_useful_test=pd.read_csv(\"review_meta_test.csv\")[\"vote_useful\"]\n",
    "\n",
    "X_test[\"vote_funny\"]=vote_funny_test\n",
    "X_test[\"vote_cool\"]=vote_cool_test\n",
    "X_test[\"vote_useful\"]=vote_useful_test\n",
    "\n",
    "X = df.drop(columns=[\"class_label\"])\n",
    "y = df[\"class_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the train set into 2 halves\n",
    "\"\"\"\n",
    "df_first_half = df.sample(frac=0.5)\n",
    "X_train_first_half = df_first_half.drop(columns=[\"class_label\"])\n",
    "y_train_first_half = df_first_half[\"class_label\"]\n",
    "\n",
    "df_second_half = df.drop(labels=df_first_half.index, axis='index')\n",
    "X_train_second_half = df_second_half.drop(columns=[\"class_label\"])\n",
    "y_train_second_half = df_second_half[\"class_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Create predictions using different classifiers</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=300, max_depth=25, n_jobs=-1, random_state=2)\n",
    "clf1.fit(X, y)\n",
    "test_predictions = clf1.predict(X_test)\n",
    "RF = pd.DataFrame(test_predictions)\n",
    "RF.index=RF.index+1\n",
    "RF=RF.reset_index()\n",
    "RF.columns=[\"Instance_id\", \"rating\"]\n",
    "RF.to_csv(\"Random_Forest_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf2.fit(X, y)\n",
    "test_predictions = clf2.predict(X_test)\n",
    "zeroR = pd.DataFrame(test_predictions)\n",
    "zeroR.index=zeroR.index+1\n",
    "zeroR=zeroR.reset_index()\n",
    "zeroR.columns=[\"Instance_id\", \"rating\"]\n",
    "zeroR.to_csv(\"Zero_R_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf3 = svm.LinearSVC(C=1, max_iter=10000)\n",
    "clf3.fit(X, y)\n",
    "test_predictions = clf3.predict(X_test)\n",
    "svc = pd.DataFrame(test_predictions)\n",
    "svc.index=svc.index+1\n",
    "svc=svc.reset_index()\n",
    "svc.columns=[\"Instance_id\", \"rating\"]\n",
    "svc.to_csv(\"Linear_SVC_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Using different base classifiers, fit the model with one half of the train set, and predict using the other half of the train set. Then repeat, switching the two halves, thus generating the train set for the stacking classifier</H4>\n",
    "\n",
    "Random Forest and SVM used the hyperparameters found via grid search as before, but Naive Bayes and neural network will not be tuned (and will instead just use hyperparameters that seem reasonable) as we will not analyse these models in our report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_for_stacker = pd.DataFrame()\n",
    "clf1 = RandomForestClassifier(n_estimators=300, max_depth=25, n_jobs=-1, random_state=2)\n",
    "clf1.fit(X_train_first_half, y_train_first_half)\n",
    "rf_base_predictions=pd.DataFrame(clf1.predict_proba(X_train_second_half))\n",
    "df_train_for_stacker[\"RF_1Star\"] = rf_base_predictions[0]\n",
    "df_train_for_stacker[\"RF_3Star\"] = rf_base_predictions[1]\n",
    "df_train_for_stacker[\"RF_5Star\"] = rf_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_for_stacker2 = pd.DataFrame()\n",
    "clf1 = RandomForestClassifier(n_estimators=300, max_depth=25, n_jobs=-1, random_state=2)\n",
    "clf1.fit(X_train_second_half, y_train_second_half)\n",
    "rf_base_predictions=pd.DataFrame(clf1.predict_proba(X_train_first_half))\n",
    "df_train_for_stacker2[\"RF_1Star\"] = rf_base_predictions[0]\n",
    "df_train_for_stacker2[\"RF_3Star\"] = rf_base_predictions[1]\n",
    "df_train_for_stacker2[\"RF_5Star\"] = rf_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train_first_half, y_train_first_half)\n",
    "gnb_base_predictions = pd.DataFrame(clf2.predict_proba(X_train_second_half))\n",
    "df_train_for_stacker[\"GNB_1Star\"] = gnb_base_predictions[0]\n",
    "df_train_for_stacker[\"GNB_3Star\"] = gnb_base_predictions[1]\n",
    "df_train_for_stacker[\"GNB_5Star\"] = gnb_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train_second_half, y_train_second_half)\n",
    "gnb_base_predictions = pd.DataFrame(clf2.predict_proba(X_train_first_half))\n",
    "df_train_for_stacker2[\"GNB_1Star\"] = gnb_base_predictions[0]\n",
    "df_train_for_stacker2[\"GNB_3Star\"] = gnb_base_predictions[1]\n",
    "df_train_for_stacker2[\"GNB_5Star\"] = gnb_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=1000)\n",
    "clf3.fit(X_train_first_half, y_train_first_half)\n",
    "nn_base_predictions = pd.DataFrame(clf3.predict_proba(X_train_second_half))\n",
    "df_train_for_stacker[\"NN_1Star\"] = nn_base_predictions[0]\n",
    "df_train_for_stacker[\"NN_3Star\"] = nn_base_predictions[1]\n",
    "df_train_for_stacker[\"NN_5Star\"] = nn_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=1000)\n",
    "clf3.fit(X_train_second_half, y_train_second_half)\n",
    "nn_base_predictions = pd.DataFrame(clf3.predict_proba(X_train_first_half))\n",
    "df_train_for_stacker2[\"NN_1Star\"] = nn_base_predictions[0]\n",
    "df_train_for_stacker2[\"NN_3Star\"] = nn_base_predictions[1]\n",
    "df_train_for_stacker2[\"NN_5Star\"] = nn_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf4 = svm.LinearSVC(C=1, max_iter=10000)\n",
    "clf4.fit(X_train_first_half, y_train_first_half)\n",
    "svm_base_predictions = pd.DataFrame(clf4.decision_function(X_train_second_half))\n",
    "df_train_for_stacker[\"SVM_1Star\"] = svm_base_predictions[0]\n",
    "df_train_for_stacker[\"SVM_3Star\"] = svm_base_predictions[1]\n",
    "df_train_for_stacker[\"SVM_5Star\"] = svm_base_predictions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf4 = svm.LinearSVC(C=1, max_iter=10000)\n",
    "clf4.fit(X_train_second_half, y_train_second_half)\n",
    "svm_base_predictions = pd.DataFrame(clf4.decision_function(X_train_first_half))\n",
    "df_train_for_stacker2[\"SVM_1Star\"] = svm_base_predictions[0]\n",
    "df_train_for_stacker2[\"SVM_3Star\"] = svm_base_predictions[1]\n",
    "df_train_for_stacker2[\"SVM_5Star\"] = svm_base_predictions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Generate attributes for the meta classifier from base classifier predictions using the test set</H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_for_stacker = pd.DataFrame()\n",
    "\n",
    "rf_base_predictions_test = pd.DataFrame(clf1.predict_proba(X_test))\n",
    "df_test_for_stacker[\"RF_1Star\"] = rf_base_predictions_test[0]\n",
    "df_test_for_stacker[\"RF_3Star\"] = rf_base_predictions_test[1]\n",
    "df_test_for_stacker[\"RF_5Star\"] = rf_base_predictions_test[2]\n",
    "\n",
    "gnb_base_predictions_test = pd.DataFrame(clf2.predict_proba(X_test))\n",
    "df_test_for_stacker[\"GNB_1Star\"] = gnb_base_predictions_test[0]\n",
    "df_test_for_stacker[\"GNB_3Star\"] = gnb_base_predictions_test[1]\n",
    "df_test_for_stacker[\"GNB_5Star\"] = gnb_base_predictions_test[2]\n",
    "\n",
    "nn_base_predictions_test = pd.DataFrame(clf3.predict_proba(X_test))\n",
    "df_test_for_stacker[\"NN_1Star\"] = nn_base_predictions_test[0]\n",
    "df_test_for_stacker[\"NN_3Star\"] = nn_base_predictions_test[1]\n",
    "df_test_for_stacker[\"NN_5Star\"] = nn_base_predictions_test[2]\n",
    "\n",
    "svm_base_predictions_test = pd.DataFrame(clf4.decision_function(X_test))\n",
    "df_test_for_stacker[\"SVM_1Star\"] = svm_base_predictions_test[0]\n",
    "df_test_for_stacker[\"SVM_3Star\"] = svm_base_predictions_test[1]\n",
    "df_test_for_stacker[\"SVM_5Star\"] = svm_base_predictions_test[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Meta classifier</H4>\n",
    "<H5>On test set</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_wal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "meta_clf_for_test = LogisticRegression(C=1, penalty='l2', max_iter=100, random_state=1)\n",
    "meta_clf_for_test.fit(pd.concat([df_train_for_stacker, df_train_for_stacker2]), pd.concat([y_train_second_half, y_train_first_half]))\n",
    "meta_prediction = meta_clf_for_test.predict(df_test_for_stacker)\n",
    "meta = pd.DataFrame(meta_prediction)\n",
    "meta.index=meta.index+1\n",
    "meta=meta.reset_index()\n",
    "meta.columns=[\"Instance_id\", \"rating\"]\n",
    "meta.to_csv(\"meta_clf_for_test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Error Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 235,  143,   97],\n",
       "       [  56,  769,  490],\n",
       "       [  23,  218, 3583]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, meta_predictions)\n",
    "#Will change between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 127,  108,  240],\n",
       "       [  17,  466,  832],\n",
       "       [   5,   55, 3764]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, RF_predictions)\n",
    "#Will change between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 204,  133,  138],\n",
       "       [  53,  708,  554],\n",
       "       [  21,  167, 3636]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, SVC_predictions)\n",
    "#Will change between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 1315, 5: 3824, 1: 475})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 5119, 1: 476, 3: 1423})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(meta_prediction)\n",
    "#bias toward 5 star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 4836, 3: 629, 1: 149})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(RF_predictions)\n",
    "#bias toward 5 star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 4328, 3: 1008, 1: 278})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(SVC_predictions)\n",
    "#bias toward 5 star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
